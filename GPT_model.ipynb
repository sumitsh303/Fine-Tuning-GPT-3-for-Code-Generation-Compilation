{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPTOoT50H3U-",
        "outputId": "ef02a4ff-72ba-4c29-b69a-18a8b8bda835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m71.7/73.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!apt-get -qq install g++"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = \"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\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "file = openai.File.create(\n",
        "    file=open(\"data.jsonl\", \"rb\"),\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "\n",
        "fine_tune = openai.FineTune.create(\n",
        "    training_file=file[\"id\"],\n",
        "    model=\"davinci\"\n",
        ")\n",
        "\n",
        "import time\n",
        "while True:\n",
        "    fine_tune = openai.FineTune.retrieve(fine_tune[\"id\"])\n",
        "\n",
        "    if fine_tune[\"status\"] == \"succeeded\":\n",
        "\n",
        "        model_id = fine_tune[\"model\"]\n",
        "        prompt = input(\"Enter your prompt (or 'exit' to quit): \")\n",
        "        if prompt.lower() == \"exit\":\n",
        "            break\n",
        "\n",
        "        completions = openai.Completion.create(\n",
        "            engine=model_id,\n",
        "            prompt=prompt,\n",
        "            stop=[\" END\"]\n",
        "        )\n",
        "        print(completions[\"choices\"][0][\"text\"])\n",
        "    else:\n",
        "\n",
        "        print(f\"Fine-tuning status: {fine_tune['status']}\")\n",
        "    time.sleep(60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "2gNF2pQcIBBH",
        "outputId": "88e45e7c-5e1e-4900-b302-42ad1e89281f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning status: pending\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-54f473834a0d>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Fine-tuning status: {fine_tune['status']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_list = openai.FineTune.list()\n",
        "status_list = [job['status'] for job in fine_tune_list['data']]\n",
        "print(len(status_list))\n",
        "print(status_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPJJ7lYgOQR0",
        "outputId": "bd6e547c-d099-4ada-d392-9210996c7238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33\n",
            "['succeeded', 'succeeded', 'succeeded', 'succeeded', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending', 'succeeded', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending', 'pending']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import subprocess\n",
        "\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = \"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\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "\n",
        "file = openai.File.create(\n",
        "    file=open(\"data.jsonl\", \"rb\"),\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "\n",
        "fine_tune = openai.FineTune.create(\n",
        "    training_file=file[\"id\"],\n",
        "    model=\"davinci\"\n",
        ")\n",
        "\n",
        "\n",
        "import time\n",
        "while True:\n",
        "    fine_tune = openai.FineTune.retrieve(fine_tune[\"id\"])\n",
        "\n",
        "\n",
        "    if fine_tune[\"status\"] == \"succeeded\":\n",
        "\n",
        "        model_id = fine_tune[\"model\"]\n",
        "\n",
        "        accumulated_code = ''\n",
        "\n",
        "        while True:\n",
        "            prompt = input(\"Enter your prompt (or 'exit' to quit): \")\n",
        "            if prompt.lower() == \"exit\":\n",
        "                break\n",
        "\n",
        "            completions = openai.Completion.create(\n",
        "                engine=model_id,\n",
        "                prompt=prompt,\n",
        "                stop=[\" END\"]\n",
        "            )\n",
        "            generated_code = completions[\"choices\"][0][\"text\"]\n",
        "\n",
        "            accumulated_code += generated_code\n",
        "\n",
        "\n",
        "        cpp_code = f'''\n",
        "        #include <iostream>\n",
        "        #include <map>\n",
        "\n",
        "        int main() {{\n",
        "\n",
        "\n",
        "            {accumulated_code}\n",
        "\n",
        "\n",
        "            return 0;\n",
        "        }}\n",
        "        '''\n",
        "\n",
        "\n",
        "        with open('temp_accumulated_code.cpp', 'w') as f:\n",
        "            f.write(cpp_code)\n",
        "\n",
        "        compile_command = [\"g++\", \"temp_accumulated_code.cpp\", \"-o\", \"output\"]\n",
        "        execution_command = [\"./output\"]\n",
        "        try:\n",
        "            subprocess.run(compile_command, check=True)\n",
        "\n",
        "            execution_output = subprocess.check_output(execution_command, stderr=subprocess.STDOUT, text=True)\n",
        "\n",
        "            print(\"Code Output:\")\n",
        "            print(execution_output)\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(\"Code Execution Error:\")\n",
        "            print(e.output)\n",
        "    else:\n",
        "        print(f\"Fine-tuning status: {fine_tune['status']}\")\n",
        "    time.sleep(60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KETQoM8-Nip1",
        "outputId": "bc0d02f6-b5db-4328-fcb9-6b3e15d747b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning status: pending\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    cpp_code = f'''\n",
        "    #include <iostream>\n",
        "    #include <map>\n",
        "\n",
        "    int main() {{\n",
        "        typedef std::map<int, int> DB;\n",
        "        DB MyDB;\n",
        "\n",
        "        {accumulated_code}\n",
        "\n",
        "        // Handling potential scenarios and input/output\n",
        "        if (!MyDB.empty()) {{\n",
        "            for (const auto& value : MyDB) {{\n",
        "                std::cout << \"Key: \" << value.first << \", Value: \" << value.second << std::endl;\n",
        "            }}\n",
        "        }} else {{\n",
        "            std::cout << \"Map is empty.\" << std::endl;\n",
        "        }}\n",
        "\n",
        "        return 0;\n",
        "    }}\n",
        "    '''"
      ],
      "metadata": {
        "id": "ZEWAydrpkk6l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}